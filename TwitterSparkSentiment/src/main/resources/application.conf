# Application Config

# Twitter App OAuth Credentials
ACCESS_TOKEN_KEY = "122528040-BKddrSVzrcmyRBKPVHBdL65mgNanVtnxJacmrOFP"
ACCESS_TOKEN_SECRET = "tu6nFiQHtlSSdJqRJE9ua4hgJ7oGBFIT8nD3zh1Gdp1Jt"
CONSUMER_KEY = "RbABZ6hZYconrA9M3rIeh8W3N"
CONSUMER_SECRET = "Vw56Lafdn7SiWwDk6M0l7e2ZmBVcYm1f4GLk6uyL5bTsWmwiY1"

# Absolute path of the Sentiment140 Training data.
TRAINING_DATA_PATH = "/Users/dan.dixey/Desktop/QBiz/Data/trainingandtestdata/training.1600000.processed.noemoticon.csv"

# Absolute path of the Sentiment140 Testing data.
TESTING_DATA_PATH = "/Users/dan.dixey/Desktop/QBiz/Data/trainingandtestdata/testdata.manual.2009.06.14.csv"

# Path to save the Naive Bayes Model of training data
MODEL_PATH = "/Users/dan.dixey/Desktop/TwitterSparkSentiment/src/main/resources/Models"
MODEL_RESULTS = "/Users/dan.dixey/Desktop/TwitterSparkSentiment/src/main/resources/Models"
TWEETS_CLASSIFIED_ABSOLUTE_PATH = ""

# Name of the file in the classpath [resources folder] which contains the stop words.
NLTK_STOPWORDS_FILE_NAME = NLTK_stopwords.txt

# Spark Streaming job runs in batches. Each batch is for the following duration.
STREAMING_MICRO_BATCH_TIME_IN_SECONDS=15

# This will be total run time of Spark Streaming job.
TOTAL_RUN_TIME_IN_MINUTES=5

// Kafka Topic Name
KAFKA_TOPIC = "ScalaTwitter"
KAFKA_OUTPUT_TOPIC = "WebUI"
